{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XOfAKfPFZtOk"
      },
      "outputs": [],
      "source": [
        "from skimage import feature\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from imutils import build_montages\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IEFlNt0tUsMR"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cv2_imshow' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image1 \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/My Drive/Colab Notebooks/parkinsons/wave/training/healthy/V01HO02.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcv2_imshow\u001b[49m(image1)\n\u001b[0;32m      3\u001b[0m imgplot \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mhist(image1\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;241m256\u001b[39m, [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m256\u001b[39m])\n\u001b[0;32m      4\u001b[0m threshold_value1, threshold_result1 \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mthreshold(image1, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv\u001b[38;5;241m.\u001b[39mTHRESH_BINARY_INV)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'cv2_imshow' is not defined"
          ]
        }
      ],
      "source": [
        "image1 = cv.imread('/content/drive/My Drive/Colab Notebooks/parkinsons/wave/training/healthy/V01HO02.png')\n",
        "cv2_imshow(image1)\n",
        "imgplot = plt.hist(image1.flatten(), 256, [0,256])\n",
        "threshold_value1, threshold_result1 = cv.threshold(image1, 150, 255, cv.THRESH_BINARY_INV)\n",
        "cv2_imshow(threshold_result1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7o8xu2mZT3tr"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ysM-pcLGTwP8"
      },
      "outputs": [],
      "source": [
        "def preprocessing(image, image_size):\n",
        "  image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "  image = cv.resize(image, (image_size,image_size))\n",
        "  image = cv.threshold(image, 0, 255, cv.THRESH_BINARY_INV | cv.THRESH_OTSU)[1]\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "60ug57piYfV1"
      },
      "outputs": [],
      "source": [
        "def load_split(path, image_size, extraction_method):\n",
        "  image_paths = list(paths.list_images(path))\n",
        "  data = []\n",
        "  labels = []\n",
        "  \n",
        "  for image_path in image_paths :\n",
        "    label = image_path.split(os.path.sep)[-2]\n",
        "    image = cv.imread(image_path)\n",
        "    image = preprocessing(image, image_size = image_size)\n",
        "\n",
        "    if extraction_method == 'hog':\n",
        "      features = quantify_image_hog(image)\n",
        "    elif extraction_method == 'lbp':\n",
        "      features = quantify_image_lbp(image)\n",
        "\n",
        "    data.append(features)\n",
        "    labels.append(label)\n",
        "\n",
        "  return (np.array(data), np.array(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HbI7OhimZkba"
      },
      "source": [
        "# Feature Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pC6epkrsZoLG"
      },
      "outputs": [],
      "source": [
        "# HOG\n",
        "def quantify_image_hog(image): # Histogram of Oriented Gradient features\n",
        "  features = feature.hog(image, orientations=9, pixels_per_cell=(10, 10), cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L1\")\n",
        "  \n",
        "  \n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U05Zp4fSZuSb"
      },
      "outputs": [],
      "source": [
        "# LBP\n",
        "def quantify_image_lbp(image): # Local Binary Pattern features\n",
        "  features = feature.local_binary_pattern(image, 24, 8, method=\"uniform\")\n",
        "  (hist, _) = np.histogram(features.flatten(), bins=np.arange(0, 27), range=(0, 26))\n",
        "  \n",
        "  hist = hist.astype(\"float\")\n",
        "  hist /= (hist.sum() + 1e-7)\n",
        "  return hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6I4TpA1akot4"
      },
      "source": [
        "# Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "I-2pe42xkm5a"
      },
      "outputs": [],
      "source": [
        "def scores(obj, predict, feature2, label2):\n",
        "    print('Accuracy   on test set: {:.3f}'.format(obj.score(feature2, label2)))\n",
        "    print('F1_score   on test set: {:.3f}'.format(f1_score(label2, predict, average='macro')))\n",
        "    print('Precision  on test set: {:.3f}'.format(precision_score(label2, predict, average='macro')))\n",
        "    print('Recall     on test set: {:.3f}'.format(recall_score(label2, predict, average='macro')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GzFx9y4DmMOV"
      },
      "outputs": [],
      "source": [
        "def test(path, resize_image_size, model):\n",
        "  testing_paths = list(paths.list_images(path))\n",
        "  images = []\n",
        "\n",
        "  for testing_path in testing_paths[:25]:\n",
        "    image = cv.imread(testing_path)\n",
        "    output = image.copy()\n",
        "    output = cv.resize(output, (128, 128))\n",
        "    \n",
        "    image = preprocessing(image, image_size = resize_image_size)\n",
        "    \n",
        "    if extraction_method == 'hog':\n",
        "      features = quantify_image_hog(image)\n",
        "    elif extraction_method == 'lbp':\n",
        "      features = quantify_image_lbp(image)\n",
        "    \n",
        "    preds = model.predict([features])\n",
        "    label = le.inverse_transform(preds)[0]\n",
        "    color = (0, 255, 0) if label == \"healthy\" else (0, 0, 255)\n",
        "    cv.putText(output, label, (3, 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    images.append(output)\n",
        "  \n",
        "  montage = build_montages(images, (128, 128), (5, 5))[0]\n",
        "  cv2_imshow(montage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ku-fSKURJC9C"
      },
      "source": [
        "# Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IC6hM_LzS_e1"
      },
      "outputs": [],
      "source": [
        "def logistic_regression(feature_train,label_train,feature_test,label_test):\n",
        "  print(\"Logistic Regression\")\n",
        "  logreg = LogisticRegression(max_iter=1000,random_state=10)\n",
        "  logreg.fit(feature_train, label_train)\n",
        "  cross_val= cross_val_score(logreg, feature_train,label_train, cv=10)\n",
        "  print(\"Cross Validation Score : \"+str(cross_val))\n",
        "  predictions = logreg.predict(feature_test)\n",
        "  scores(logreg,predictions,feature_test,label_test)\n",
        "  cm = confusion_matrix(label_test,predictions)\n",
        "  cr = classification_report(label_test, predictions)\n",
        "  print(cm)\n",
        "  print(cr)\n",
        "  print(\"------------------------------------------------------------------\")\n",
        "  print()\n",
        "  return logreg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VkIfQIJvd3V3"
      },
      "outputs": [],
      "source": [
        "def linear_svc(feature_train,label_train,feature_test,label_tes):\n",
        "  print(\"Linear SVC\")\n",
        "  svc = LinearSVC(max_iter=10000,random_state=10,C=10.0)\n",
        "  svc.fit(feature_train, label_train)\n",
        "  cross_val= cross_val_score(svc, feature_train,label_train, cv=10)\n",
        "  print(\"Cross Validation Score : \"+str(cross_val))\n",
        "  predictions = svc.predict(feature_test)\n",
        "  scores(svc,predictions,feature_test,label_test)\n",
        "  cm = confusion_matrix(label_test,predictions)\n",
        "  cr = classification_report(label_test, predictions)\n",
        "  print(cm)\n",
        "  print(cr)\n",
        "  print(\"------------------------------------------------------------------\")\n",
        "  print()\n",
        "  return svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ySCuN7yReoI7"
      },
      "outputs": [],
      "source": [
        "def random_forest(feature_train, label_train, feature_test, label_test):\n",
        "  print(\"Random Forest\")\n",
        "  rfc = RandomForestClassifier(n_estimators=100,random_state=10)\n",
        "  rfc.fit(feature_train, label_train)\n",
        "  cross_val= cross_val_score(rfc, feature_train,label_train, cv=10)\n",
        "  print(\"Cross Validation Score : \"+str(cross_val))\n",
        "  predictions = rfc.predict(feature_test)\n",
        "  scores(rfc,predictions,feature_test,label_test)\n",
        "  cm = confusion_matrix(label_test,predictions)\n",
        "  cr = classification_report(label_test, predictions)\n",
        "  print(cm)\n",
        "  print(cr)\n",
        "  print(\"------------------------------------------------------------------\")\n",
        "  print()\n",
        "  return rfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OatCocdVfZDI"
      },
      "outputs": [],
      "source": [
        "def KNN(feature_train, label_train, feature_test, label_test):\n",
        "  print(\"KNN\")\n",
        "  knn = KNeighborsClassifier(n_neighbors=11,weights='distance',algorithm='auto')\n",
        "  knn.fit(feature_train,label_train)\n",
        "  cross_val= cross_val_score(knn, feature_train,label_train, cv=10)\n",
        "  print(\"Cross Validation Score : \"+str(cross_val))\n",
        "  predictions = knn.predict(feature_test)\n",
        "  scores(knn,predictions,feature_test,label_test)\n",
        "  cm = confusion_matrix(label_test,predictions)\n",
        "  cr = classification_report(label_test, predictions)\n",
        "  print(cm)\n",
        "  print(cr)\n",
        "  print(\"------------------------------------------------------------------\")\n",
        "  print()\n",
        "  return knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qgOKPD2Hf02O"
      },
      "outputs": [],
      "source": [
        "def MLP(feature_train, label_train, feature_test, label_test):\n",
        "  print(\"MLP\")\n",
        "  mlp = MLPClassifier(hidden_layer_sizes=10, activation='relu',solver='lbfgs',batch_size='auto', learning_rate_init=0.0001, max_iter=10000,early_stopping=False)\n",
        "  mlp.fit(feature_train,label_train)\n",
        "  cross_val= cross_val_score(mlp, feature_train,label_train, cv=10)\n",
        "  print(\"Cross Validation Score : \"+str(cross_val))\n",
        "  predictions = mlp.predict(feature_test)\n",
        "  scores(mlp, predictions,feature_test,label_test)\n",
        "  cm = confusion_matrix(label_test,predictions)\n",
        "  cr = classification_report(label_test, predictions)\n",
        "  print(cm)\n",
        "  print(cr)\n",
        "  print(\"------------------------------------------------------------------\")\n",
        "  print()\n",
        "  return mlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eWuhxC2ccrdC"
      },
      "source": [
        "# Using HOG 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cMNHRpCIcvjA"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/drive/My Drive/Colab Notebooks/parkinsons/wave'\n",
        "\n",
        "trainingPath = os.path.join(dataset_dir, \"training\")\n",
        "testingPath = os.path.join(dataset_dir, \"testing\")\n",
        "\n",
        "print(trainingPath)\n",
        "print(testingPath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tP-G1j6_icF3"
      },
      "outputs": [],
      "source": [
        "resize_image_size = 128\n",
        "extraction_method = 'hog'\n",
        "\n",
        "(feature_train, label_train) = load_split(path = trainingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "(feature_test, label_test) = load_split(path = testingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "\n",
        "print(\"Data loaded!\")\n",
        "le = LabelEncoder()\n",
        "label_train = le.fit_transform(label_train)\n",
        "label_test = le.transform(label_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QD0RyEru6SC7"
      },
      "outputs": [],
      "source": [
        "print(label_train)\n",
        "print(label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JieENKlJl8QM"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xcx_0agqM3TM"
      },
      "outputs": [],
      "source": [
        "logreg = logistic_regression(feature_train,label_train,feature_test,label_test)\n",
        "svc = linear_svc(feature_train,label_train,feature_test,label_test)\n",
        "rfc = random_forest(feature_train,label_train,feature_test,label_test)\n",
        "knn = KNN(feature_train,label_train,feature_test,label_test)\n",
        "mlc = MLP(feature_train,label_train,feature_test,label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bqlZJ2I_l_5Z"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "letltAwjmEpU"
      },
      "outputs": [],
      "source": [
        "# Testing Logistic Regression\n",
        "images = test(testingPath,resize_image_size,logreg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vuRMwVbdwVRT"
      },
      "outputs": [],
      "source": [
        "# Testing SVC\n",
        "images = test(testingPath,resize_image_size,svc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vvq4-jy3wV2n"
      },
      "outputs": [],
      "source": [
        "# Testing Random Forest\n",
        "images = test(testingPath,resize_image_size,rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5PJRHNjxgWGk"
      },
      "outputs": [],
      "source": [
        "# Testing KNN\n",
        "images = test(testingPath,resize_image_size,knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WzaJPFkvjnm9"
      },
      "outputs": [],
      "source": [
        "# Testing MLC\n",
        "images = test(testingPath,resize_image_size,mlc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ph_0KnfI42zY"
      },
      "source": [
        "# Using HOG 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mIbi6APr5AAZ"
      },
      "outputs": [],
      "source": [
        "resize_image_size = 300\n",
        "extraction_method = 'hog'\n",
        "\n",
        "(feature_train, label_train) = load_split(path = trainingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "(feature_test, label_test) = load_split(path = testingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "\n",
        "print(\"Data loaded!\")\n",
        "le = LabelEncoder()\n",
        "label_train = le.fit_transform(label_train)\n",
        "label_test = le.transform(label_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VgzpOkwc5HYN"
      },
      "outputs": [],
      "source": [
        "print(label_train)\n",
        "print(label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gFtLfv2i5THM"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tNfHyKJUPZyl"
      },
      "outputs": [],
      "source": [
        "logreg = logistic_regression(feature_train,label_train,feature_test,label_test)\n",
        "svc = linear_svc(feature_train,label_train,feature_test,label_test)\n",
        "rfc = random_forest(feature_train,label_train,feature_test,label_test)\n",
        "knn = KNN(feature_train,label_train,feature_test,label_test)\n",
        "mlc = MLP(feature_train,label_train,feature_test,label_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9CaR2A1b52eI"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "riIl_K2A54fA"
      },
      "outputs": [],
      "source": [
        "# Testing Logistic Regression\n",
        "images = test(testingPath,resize_image_size,logreg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rgBg5MH85_PU"
      },
      "outputs": [],
      "source": [
        "# Testing SVC\n",
        "images = test(testingPath,resize_image_size,svc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9sQInU0g6CVz"
      },
      "outputs": [],
      "source": [
        "# Testing Random Forest\n",
        "images = test(testingPath,resize_image_size,rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "z7WOh-k2glg1"
      },
      "outputs": [],
      "source": [
        "# Testing KNN\n",
        "images = test(testingPath,resize_image_size,knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1TbMturag2c0"
      },
      "outputs": [],
      "source": [
        "# Testing MLC\n",
        "images = test(testingPath,resize_image_size,mlc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EqkCq_Nt7Dw1"
      },
      "source": [
        "# Using LBP 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3Gjo-Gmm7H1q"
      },
      "outputs": [],
      "source": [
        "resize_image_size = 128\n",
        "extraction_method = 'lbp'\n",
        "\n",
        "(feature_train, label_train) = load_split(path = trainingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "(feature_test, label_test) = load_split(path = testingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "\n",
        "print(\"Data loaded!\")\n",
        "le = LabelEncoder()\n",
        "label_train = le.fit_transform(label_train)\n",
        "label_test = le.transform(label_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2_L9mKpm7VOh"
      },
      "outputs": [],
      "source": [
        "print(label_train)\n",
        "print(label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BfGFzto_7a03"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eRerQKeuPrlQ"
      },
      "outputs": [],
      "source": [
        "logreg = logistic_regression(feature_train,label_train,feature_test,label_test)\n",
        "svc = linear_svc(feature_train,label_train,feature_test,label_test)\n",
        "rfc = random_forest(feature_train,label_train,feature_test,label_test)\n",
        "knn = KNN(feature_train,label_train,feature_test,label_test)\n",
        "mlc = MLP(feature_train,label_train,feature_test,label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G6dma8HP_P8D"
      },
      "source": [
        "## Testing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rxVYSUIn_XXL"
      },
      "outputs": [],
      "source": [
        "# Testing logreg\n",
        "images = test(testingPath,resize_image_size,logreg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XSQhUYfR_YS8"
      },
      "outputs": [],
      "source": [
        "# Testing SVC\n",
        "images = test(testingPath,resize_image_size,svc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "P4a_cekP_xR5"
      },
      "outputs": [],
      "source": [
        "# Testing Random Forest\n",
        "images = test(testingPath,resize_image_size,rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gx3k1FRVgqj6"
      },
      "outputs": [],
      "source": [
        "# Testing KNN\n",
        "images = test(testingPath,resize_image_size,knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "q2A3ukT7g4ZK"
      },
      "outputs": [],
      "source": [
        "# Testing MLC\n",
        "images = test(testingPath,resize_image_size,mlc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-nAkO0a4Q7hP"
      },
      "source": [
        "# Using LBP 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RAFV-RTUQ_sG"
      },
      "outputs": [],
      "source": [
        "resize_image_size = 300\n",
        "extraction_method = 'lbp'\n",
        "\n",
        "(feature_train, label_train) = load_split(path = trainingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "(feature_test, label_test) = load_split(path = testingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "\n",
        "print(\"Data loaded!\")\n",
        "le = LabelEncoder()\n",
        "label_train = le.fit_transform(label_train)\n",
        "label_test = le.transform(label_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0aJTU7RrRJqh"
      },
      "outputs": [],
      "source": [
        "print(label_train)\n",
        "print(label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m8Uod38WRIiD"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hmtQ8G_dRQV-"
      },
      "outputs": [],
      "source": [
        "logreg = logistic_regression(feature_train,label_train,feature_test,label_test)\n",
        "svc = linear_svc(feature_train,label_train,feature_test,label_test)\n",
        "rfc = random_forest(feature_train,label_train,feature_test,label_test)\n",
        "knn = KNN(feature_train,label_train,feature_test,label_test)\n",
        "mlc = MLP(feature_train,label_train,feature_test,label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cb6ZYAjbRT1U"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hnuH7f_4RVjI"
      },
      "outputs": [],
      "source": [
        "# Testing Logistic Regression\n",
        "images = test(testingPath,resize_image_size,logreg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Y8yr68WaRY29"
      },
      "outputs": [],
      "source": [
        "# Testing SVC\n",
        "images = test(testingPath,resize_image_size,svc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cvp-Hkr3RgZq"
      },
      "outputs": [],
      "source": [
        "# Testing Random Forest\n",
        "images = test(testingPath,resize_image_size,rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZV-rL5AwgoRY"
      },
      "outputs": [],
      "source": [
        "# Testing KNN\n",
        "images = test(testingPath,resize_image_size,knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zHa2S3L9g6JX"
      },
      "outputs": [],
      "source": [
        "# Testing MLC\n",
        "images = test(testingPath,resize_image_size,mlc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hNAYmt4hk10Y"
      },
      "source": [
        "# Kesimpulan\n",
        "HOG 128 dgn KNN(11) menghasilkan akurasi 83%\n",
        "\n",
        "HOG 300 dgn LinearSVC menghasilkan akurasi 73%\n",
        "\n",
        "LBP 128 dgn KNN(11) menghasilkan akurasi 60%\n",
        "\n",
        "LBP 300 dgn RandomForest menghasilkan akurasi 70%\n",
        "\n",
        "Dapat disimpulkan bahwa ukuran citra yang digunakan tidak banyak mempengaruhi\n",
        "hasil prediksi suatu algoritma. yang menentukan adalah bagaimana suatu fitur pada citra itu dapat diekstraksi, sehingga algoritma dapat mempelajari dan mengenali fitur dengan baik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oibU6UM2k5sI"
      },
      "source": [
        "# Menambahkan data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tHYXteIYQf54"
      },
      "source": [
        "## Data Sehat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-5zDd_9alJno"
      },
      "outputs": [],
      "source": [
        "sehat = cv.imread('/content/drive/My Drive/IMG_20200925_130819.jpg')\n",
        "cv2_imshow(sehat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Mzmc0yuJ6-bB"
      },
      "outputs": [],
      "source": [
        "sehat1 = cv.cvtColor(sehat,cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow(sehat1)\n",
        "sehat1 = cv.equalizeHist(sehat1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XG7tizJi7UlR"
      },
      "outputs": [],
      "source": [
        " sehat1 = cv.medianBlur(sehat1,3)\n",
        " cv2_imshow(sehat1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4oaUTbZn9Dc6"
      },
      "outputs": [],
      "source": [
        "threshold_value, threshold_result = cv.threshold(sehat1, 3, 255, cv.THRESH_BINARY_INV) \n",
        "cv2_imshow(threshold_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2gWotmUy-sda"
      },
      "outputs": [],
      "source": [
        "\n",
        "sehat2 = cv.dilate(threshold_result,np.ones((5,5),np.uint8),iterations = 5)\n",
        "cv2_imshow(sehat2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zd9CMR_pBCpa"
      },
      "outputs": [],
      "source": [
        "contours, hierarchy = cv.findContours(sehat2, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "area_array=[]\n",
        "for index,contour in enumerate(contours):\n",
        "  x,y,w,h = cv.boundingRect(contour)\n",
        "  area = cv.contourArea(contour)\n",
        "  area_array.append([index,area,w,h])\n",
        "\n",
        "df_area =pd.DataFrame(area_array)\n",
        "df_area.columns =['index','area','width','height']\n",
        "df_sort=df_area.sort_values(by=['area'],ascending=False)\n",
        "df_sort.head(50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ksZPuhpdDV3W"
      },
      "outputs": [],
      "source": [
        "test = df_area['area']\n",
        "array=[]\n",
        "directory_save = '/content/drive/My Drive/Colab Notebooks/parkinsons/wave/training/healthy'\n",
        "\n",
        "for i,va in enumerate(test):\n",
        "  if test[i] > 50000:\n",
        "    array.append(i)\n",
        "\n",
        "array.sort()\n",
        "print(array)\n",
        "os.chdir(directory_save)\n",
        "\n",
        "for i, va in enumerate(array):\n",
        "  x,y,w,h =cv.boundingRect(contours[va])\n",
        "  wave= sehat[y:y+h, x:x+w]\n",
        "  resized= cv.resize(wave,(512,220),interpolation = cv.INTER_AREA)\n",
        "  cv.imwrite('wave{}.png'.format(i),resized)\n",
        "\n",
        "print(os.listdir(directory_save))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pzDIm_7vQmTH"
      },
      "source": [
        "## Data Parkinson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Og836a7GIreR"
      },
      "outputs": [],
      "source": [
        "sakit = cv.imread('/content/drive/My Drive/IMG_20200925_130639.jpg')\n",
        "cv2_imshow(sakit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iJMzrkBPJBCX"
      },
      "outputs": [],
      "source": [
        "sakit1 = cv.cvtColor(sakit,cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow(sakit1)\n",
        "sakit1 = cv.equalizeHist(sakit1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hFq3SjdpJzqx"
      },
      "outputs": [],
      "source": [
        " sakit1 = cv.medianBlur(sakit1,3)\n",
        " cv2_imshow(sakit1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RrDTqjfRKHC4"
      },
      "outputs": [],
      "source": [
        "threshold_value, threshold_result = cv.threshold(sakit1, 5, 255, cv.THRESH_BINARY_INV) \n",
        "cv2_imshow(threshold_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "L-YaQz4QKTe8"
      },
      "outputs": [],
      "source": [
        "erosion = cv.erode(threshold_result,np.ones((1,1),np.uint8),iterations =1)\n",
        "cv2_imshow(erosion)\n",
        "sakit2 = cv.dilate(erosion,np.ones((5,5),np.uint8),iterations = 7)\n",
        "cv2_imshow(sakit2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hyBJFwbyL9Hy"
      },
      "outputs": [],
      "source": [
        "contours, hierarchy = cv.findContours(sakit2, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "area_array=[]\n",
        "for index,contour in enumerate(contours):\n",
        "  x,y,w,h = cv.boundingRect(contour)\n",
        "  area = cv.contourArea(contour)\n",
        "  area_array.append([index,area,w,h])\n",
        "\n",
        "df_area =pd.DataFrame(area_array)\n",
        "df_area.columns =['index','area','width','height']\n",
        "df_sort=df_area.sort_values(by=['area'],ascending=False)\n",
        "df_sort.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HgyZvdnHMKRe"
      },
      "outputs": [],
      "source": [
        "test = df_area['area']\n",
        "array=[]\n",
        "directory_save = '/content/drive/My Drive/Colab Notebooks/parkinsons/wave/training/parkinson'\n",
        "\n",
        "for i,va in enumerate(test):\n",
        "  if test[i] > 80000:\n",
        "    array.append(i)\n",
        "\n",
        "array.sort()\n",
        "print(array)\n",
        "os.chdir(directory_save)\n",
        "\n",
        "for i, va in enumerate(array):\n",
        "  x,y,w,h =cv.boundingRect(contours[va])\n",
        "  wave= sakit[y:y+h, x:x+w]\n",
        "  \n",
        "  resized= cv.resize(wave,(512,220),interpolation = cv.INTER_AREA)\n",
        "  cv.imwrite('wave{}.png'.format(i),resized)\n",
        "\n",
        "print(os.listdir(directory_save))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mwUWIwZXQtlu"
      },
      "source": [
        "## Load data baru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ktV9AGVPPS8P"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/drive/My Drive/Colab Notebooks/parkinsons/wave'\n",
        "\n",
        "trainingPath = os.path.join(dataset_dir, \"training\")\n",
        "testingPath = os.path.join(dataset_dir, \"testing\")\n",
        "\n",
        "print(trainingPath)\n",
        "print(testingPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "D0z98hRRPVj6"
      },
      "outputs": [],
      "source": [
        "resize_image_size = 128\n",
        "extraction_method = 'hog'\n",
        "\n",
        "(feature_train, label_train) = load_split(path = trainingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "(feature_test, label_test) = load_split(path = testingPath, image_size= resize_image_size, extraction_method = extraction_method)\n",
        "\n",
        "print(\"Data loaded!\")\n",
        "le = LabelEncoder()\n",
        "label_train = le.fit_transform(label_train)\n",
        "label_test = le.transform(label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XQJhRjw6Q7Mr"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nwmICQNEPogC"
      },
      "outputs": [],
      "source": [
        "logreg = logistic_regression(feature_train,label_train,feature_test,label_test)\n",
        "svc = linear_svc(feature_train,label_train,feature_test,label_test)\n",
        "rfc = random_forest(feature_train,label_train,feature_test,label_test)\n",
        "knn = KNN(feature_train,label_train,feature_test,label_test)\n",
        "mlc = MLP(feature_train,label_train,feature_test,label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4INGANWfQ_RX"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wVvSX5tCQ17E"
      },
      "outputs": [],
      "source": [
        "# Testing Logistic Regression\n",
        "images = test(testingPath,resize_image_size,logreg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2cRsHzlIQ3QY"
      },
      "outputs": [],
      "source": [
        "# Testing SVC\n",
        "images = test(testingPath,resize_image_size,svc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Lhn02t9aQ3nC"
      },
      "outputs": [],
      "source": [
        "# Testing Random Forest\n",
        "images = test(testingPath,resize_image_size,rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cFOlVrJkQ4ME"
      },
      "outputs": [],
      "source": [
        "# Testing KNN\n",
        "images = test(testingPath,resize_image_size,knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UJNJfbkMQ4cn"
      },
      "outputs": [],
      "source": [
        "# Testing MLC\n",
        "images = test(testingPath,resize_image_size,mlc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yZFUSARmR9uj"
      },
      "source": [
        "#Kesimpulan\n",
        "Bahwa dengan menambahkan data gambar baru pada dataset dapat mempengaruhi hasil prediksi algoritma.\n",
        "\n",
        "Pada hampir semua algoritma yang digunakan mengalami kenaikan score akurasi prediksi, kecuali pada RandomForest yang justru turun.\n",
        "\n",
        "semakin banyak data yang digunakan untuk training maka algoritma dapat semakin banyak mempelajari variasi  fitur-fitur, sehingga tidak terjadi overfitting terhadap data latih dan akan dapat memprediksi data lain yang lebih kompleks"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7o8xu2mZT3tr",
        "HbI7OhimZkba",
        "6I4TpA1akot4",
        "Ku-fSKURJC9C",
        "eWuhxC2ccrdC",
        "ph_0KnfI42zY",
        "EqkCq_Nt7Dw1"
      ],
      "name": "Assignment#13.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "q2env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
